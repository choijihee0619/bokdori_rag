# bokdori_rag

# 🐶 노인을 위한 복도리 AI 강아지 비서 인형 프로젝트

---

## 1. 프로젝트 개요

복도리 AI 비서 인형은 노인의 일상 안전과 정서적 돌봄, 금융 사기 예방, 소통 강화를 위해 카메라/마이크/스피커를 탑재한 인형형 IoT 기기와 AI 기반 백엔드 시스템이 통합된 서비스입니다. 음성/영상 인식, LLM 대화, 감정분석, 금융퀴즈, 실시간 안전 모니터링 등 다양한 기능을 제공합니다.

---

## 2. 주요 기능 및 흐름

### 2-1. 카메라 객체 인식 (YOLO)

#### 역할 및 시나리오

* **24시간 동작**: 실시간으로 카메라 입력 모니터링
* **사람 인식**:

  * YOLO 모델로 '사람' 감지 시,
  * LLM이 시간대에 맞는 인사 및 건강 질문 자동 생성/발화
  * 객체 우선순위(예: 음식, 감정 등) 따라 맞춤 발화
  * 주요 이벤트(존재 여부, 식사, 감정 등) DB 저장
* **낙상 감지**:

  * 낙상 시나리오 학습/탑재
  * 낙상 징후 감지 시 대화 시도, 반응 없으면 가족·관리자 알림

### 2-2. 음성 대화 (STT, TTS, LLM)

* **Wakeword("복돌아", "복도라", 등) 인식**

  * Picovoice 등 wakeword engine 사용
* **다중턴, 역할 기반 대화**

  * LLM 프롬프트 기반 감정/정보/상황 맞춤 대화
* **음성 감지**

  * VAD(Voice Activity Detection)로 음성 시작·끝 자동 감지
* **STT**: 음성→텍스트 변환 (Google, Whisper 등)
* **TTS**: 텍스트→음성 변환 (Google, Naver, ElevenLabs 등)

### 2-3. 금융퀴즈 및 보이스피싱 예방

* **객체 인식 후, 일정 시간에 맞춰 자동 발화**
* **금융 퀴즈/시나리오**

  * RAG(지식검색)로 사전 저장된 시나리오/퀴즈 선택
  * LLM이 사용자 상황에 맞게 출력
* **보이스피싱 시나리오 대응**

  * 위험 행동/의심 상황 발생 시, 경고/상담 유도

### 2-4. 감정일기/대화 분석 웹

* **DB(슈퍼베이스 또는 몽고DB)에 일일 대화/감정 저장**
* **GPT API를 통해 일기 형식 감정분석/요약**
* **웹 프론트(Bolt 등)에서 감정일기 조회/시각화**

---

## 3. 사용 기술/AI 모델

| 구분     | 주요 기술/툴                    | 설명                 |
| ------ | -------------------------- | ------------------ |
| 객체인식   | YOLOv8, Ultralytics        | 실시간 인물/이벤트 감지      |
| 음성 인식  | Picovoice, Google STT, VAD | 웨이크워드/음성분할/텍스트변환   |
| 음성 합성  | Google TTS, Naver CLOVA    | 텍스트→음성             |
| LLM    | OpenAI GPT-4.1-nano        | 자연어 대화/상황별 응답      |
| RAG    | LangChain+Pinecone         | 금융 퀴즈/시나리오 검색      |
| DB     | Supabase(추천) or MongoDB    | 대화, 감정, 이벤트, 알림 저장 |
| 감정일기분석 | GPT API                    | 대화내용 감정분석/요약       |
| 웹 프론트  | Bolt(HTML/CSS/JS)          | 일기/상태 시각화          |
| 백엔드    | FastAPI                    | API 통신             |

---

## 4. 시스템 구조도 (텍스트 버전)

```
[인형(카메라/마이크/스피커)]
    │         │
    ▼         ▼
[YOLO 객체인식]    [Wakeword/VAD]
    │         │
    ▼         ▼
[이벤트 발생]      [음성 녹음]
    │         │
    └──→ [STT 변환] ───────────────┐
          │                       │
[객체정보+텍스트]                 [텍스트]
    │                             │
    └────── [백엔드 API 서버] ───────┘
                │
         ┌──────┼─────────┐
         │    LangChain   │
         │  (GPT-4.1-nano │
         │   + Pinecone)  │
         └──────┬─────────┘
                │
      [슈퍼베이스/몽고DB 기록]
                │
          [TTS 변환]
                │
         [스피커로 출력]
```

* **웹(감정일기)**:

  * \[DB] ↔ \[GPT 감정요약] ↔ \[웹(Bolt) 시각화]

---

## 5. 개발/운영 단계(예시)

1. YOLO 객체인식 및 낙상 감지 모델 튜닝/테스트
2. Wakeword+STT+TTS+VAD 연동 및 안정화
3. LangChain+GPT-4.1-nano+RAG 시나리오 챗봇 개발
4. DB(Supabase) 설계 및 데이터 연동, 감정일기 자동화
5. Bolt 웹 UI와 백엔드 API 연결
6. 통합 테스트 및 사용자 피드백 반영

---

## 6. 예상 효과 및 가치

* 노인 안전 및 돌봄 효율 대폭 향상(실시간 감시, 낙상 예방)
* 정서 지원(대화, 감정일기), 고독감 완화
* 금융사기 위험 예방, 자산보호
* 가족/관리자와의 소통·관리 채널 강화
* 쉽고 친근한 UI, 저렴한 구축·운영비

---

## 7. 향후 확장 가능성

### 7-1. RAG를 활용한 고급 감정일기분석

현재 복도리는 기본적인 감정분석 및 일기 저장 기능을 제공하지만, 향후 다음과 같은 고급 감정분석 기능으로 확장 가능합니다:

* **RAG 기반 감정 패턴 검색**: 
  * 과거 유사한 감정 상태와 대화를 벡터 임베딩으로 저장 및 검색
  * "지난번 내가 불안해했을 때는 어떤 대화를 나눴나요?"와 같은 복잡한 감정 질의 응답
  * 감정 상태별 맞춤형 대화 전략 자동 적용

* **장기 감정 트렌드 분석**:
  * 주/월별 감정 변화 패턴 분석 및 시각화
  * 특정 상황/키워드와 감정 상태 간 상관관계 자동 발견
  * 우울/불안 증상의 조기 감지 및 예방적 개입

* **맞춤형 정서 지원 시스템**:
  * 개인별 효과적인 정서 지원 방법 자동 학습
  * "지난번에 기분이 좋아졌던 활동"을 기억하고 추천
  * 가족과의 감정 소통 브리지 역할

이러한 고급 감정분석 시스템은 노인의 정서적 건강을 장기적으로 모니터링하고 지원하는 데 큰 가치가 있으며, 복도리의 차별화된 경쟁력이 될 수 있습니다.

---

## < 최지희 담당 - LangChain RAG LLM >
# 복도리 AI 인형 프로젝트: 금융교육/사기예방 시나리오 챗봇 구조 및 기술 선택 정리

## 1. LangChain 사용 이유와 LangGraph 비교

### LangChain의 특징 및 채택 이유

* 다양한 대형언어모델(LLM)과 검색엔진, 데이터베이스와의 연동이 쉽다.
* RAG(Retrieval-Augmented Generation) 파이프라인 구축에 최적화되어 있다.
* 프롬프트 템플릿, 체인, 에이전트, 임베딩 등 챗봇에 필요한 기능을 쉽게 조합·커스터마이즈할 수 있다.
* FastAPI, Streamlit 등 Python 생태계와의 통합과 협업이 용이하다.
* Pinecone, Meilisearch 등 외부 데이터베이스 및 검색엔진 연동 공식 지원.
* 현업 및 오픈소스 AI 챗봇에서 RAG-LLM 연결의 표준 도구로 가장 널리 사용된다.

### LangGraph와의 비교

* LangGraph는 LangChain의 확장으로, 멀티에이전트 워크플로우·분기·그래프 기반 대화 흐름 설계에 특화.
* 복도리 챗봇의 1차 목표는 시나리오/FAQ 기반 RAG 구조와 단일 LLM 응답이므로 복잡한 그래프 분기 구조는 필요성이 낮다.
* 단순 RAG+LLM+시나리오 챗봇 구현에는 LangChain이 문서, 예제, 협업 등 실무에 훨씬 적합하다.

## 2. LLM(대형언어모델) 선정 및 활용 목적

### 복도리 전체 프로젝트에서 LLM 활용 목적

* 노인 사용자의 자연스러운 일상 대화, 질의응답, 금융교육, 사기예방 상담 등 다양한 기능을 유연하게 처리한다.
* 사전 시나리오 외에도, 새로운 자연어 질문에 대해 AI가 맥락을 파악해 적절히 안내하고 조언할 수 있다.
* 감정일기, 건강·생활상담 등 맞춤형 답변 생성도 실시간 가능하다.

### 금융사기 예방 및 금융 퀴즈 파트에서 LLM이 필요한 이유

* 금융사기 사례, 예방법, 경고문, 실제 사례 등 다양한 FAQ·시나리오를 준비해도 실제 노인 사용자는 다양한 표현·상황으로 질문한다.
* LLM을 활용하면 질문 표현이 달라도 의미와 문맥을 이해하고 적합한 답변 제공이 가능하다.
* 금융 퀴즈, 시나리오 기반 상담도 LLM이 상황별로 유연하게 변형·확장해 자연스럽고 몰입도 높은 교육이 가능하다.
* 사기 위험 징후 포착 시, LLM이 사용자의 상태·맥락을 반영한 맞춤 경고·상담을 생성할 수 있다.
* 최신 LLM일수록 최신 금융사기 수법, 신종 금융 사례 등 도메인 지식이 더 잘 반영된다.
* LLM만으로는 도메인 특화 지식, 최신 정보 반영, 사실 정확성이 부족할 수 있기 때문에 RAG와 결합해야 한다(아래 3번).

## 3. RAG(Retrieval-Augmented Generation) 구조와 Pinecone(벡터데이터베이스) 사용 목적

* RAG는 LLM이 자체로 생성하는 답변만으로는 도메인 지식, 최신 정보, 사실성에 한계가 있으므로,
  외부 데이터베이스(FAQ, 시나리오, 금융상담, 금융 퀴즈 등)에서 '의미적으로 관련 있는' 문서를 벡터 임베딩 기반으로 검색·추출하고, 이를 LLM에 함께 입력하여 더 정확하고 신뢰도 높은 답변을 생성하는 구조이다.
* RAG의 도입 목적 중 하나는 LLM의 도메인 지식 한계 및 knowledge cut-off 문제(최신 정보 반영 불가 등)를 보완하여, 항상 최신/정확한 정보를 활용하도록 하는 것이다.
* Pinecone은 임베딩된 텍스트 벡터를 저장·관리·검색하는 대표적인 벡터 데이터베이스이다.
* 수십만·수백만 건의 문서 중에서도 빠르고 효율적으로 의미 유사도가 높은 데이터를 실시간 검색할 수 있다.
* Pinecone을 쓰는 이유:

  * 다양한 질의(오타, 표현 변화, 구어체 등)에도 의미가 비슷한 답변/시나리오/상담 문서를 찾을 수 있다.
  * 금융사기·금융상담 시나리오, 금융교육 FAQ 등 유사도 높은 대화문 추출로 LLM의 정확도·신뢰성을 높인다.
  * 대량의 시나리오·퀴즈 데이터가 누적되어도 문맥 기반 검색이 필요하다.
  * RAG 구조에서 LLM knowledge cut-off, 도메인 특화 한계, 최신성·정확성 문제를 실질적으로 보완한다.

## 4. Meilisearch 역할 및 활용

* Meilisearch는 오픈소스 키워드·텍스트 일치 기반 초고속 검색엔진이다.
* 챗봇 RAG 파이프라인보다는, 운영·관리·검색 UI 또는 프론트엔드에서 목록/필터/검색 기능에 적합하다.
* 대표적 활용 예시:

  * 금융 퀴즈, 상담 시나리오, 공지사항 등 특정 키워드나 카테고리로 문서를 빠르게 검색·필터
  * 운영자/관리자 UI에서 전체 시나리오, 최근 등록/수정 문서, 특정 키워드 포함 문서 목록 제공
  * 프론트엔드에서 "보이스피싱 관련 시나리오만 보기", "계좌번호가 포함된 금융퀴즈만 검색" 등 빠른 필터·정확 매칭에 최적
* Meilisearch는 일반 텍스트 기반 검색, Pinecone은 의미 기반(임베딩) 검색으로, 두 시스템을 병행 활용하면 사용자 편의성과 운영 효율성을 동시에 높일 수 있다.

---

### 구조도 (텍스트 기반)

```
[사용자 입력]
    │
    ├── Pinecone(벡터DB)
    │       │
    │       └── [의미기반 유사 문서 추출] ──> LLM(GPT-4.1-nano) ──> [맞춤형 답변 생성]
    │
    └── Meilisearch(검색엔진)
            │
            └── [키워드/카테고리 기반 빠른 목록·필터링] ──> [운영자/사용자 UI에 목록·검색 제공]
```

## 5. 종합

* 복도리 금융교육/사기예방 시나리오 챗봇의 전체 구조는 다음과 같다.

  * 사용자 질의·대화: Pinecone(임베딩 벡터 데이터베이스) 기반 의미검색 + RAG + LLM으로 맞춤 답변
  * 운영/관리자·프론트엔드: Meilisearch(키워드/카테고리 검색엔진) 기반 초고속 목록·필터·검색
  * 전체 파이프라인 표준화와 협업/유지보수 효율성을 위해 LangChain을 중심으로 구현
* LLM 단독 사용은 최신 정보 부족·도메인 한계·사실성 미흡 문제, RAG와 Pinecone 결합으로 보완
* Pinecone(임베딩 벡터 DB)과 Meilisearch(키워드 검색엔진) 병행 도입은 실제 현업 AI 챗봇 개발에서도 검증된 구조이며, 분업, 유지보수, 성능 등 다양한 측면에서 장점이 크다.

---

## 6. 개발 파일 구조 및 팀 협업/테스트 전략

### 1) 설계 원칙

* REST API 기반으로 각 파트를 분리하여 개발
* 입력/출력은 텍스트(JSON)로 통일, 음성(STT) 없이도 완전 테스트 가능
* LangChain, RAG, 벡터DB, 검색엔진, LLM 등은 각각 별도 모듈로 분리
* 환경변수, API 키 등은 .env 파일로 분리 관리
* 추후 전체 통합 시, 입출력 포맷(예: {"query": "질문"}, {"answer": "답변"})만 맞추면 충돌 없이 합칠 수 있음

### 3) 파일 구조 및 모듈화

```
bokdori_rag_chatbot/
├── main.py                     # FastAPI 실행, API 엔드포인트
├── services/
│   └── chatbot_service.py      # LangChain RAG+LLM 핵심 로직 (금융교육/사기예방 포함)
├── utils/
│   ├── rag_utils.py            # 임베딩, Pinecone 관련 함수
│   ├── search_utils.py         # Meilisearch 연동/검색 함수
│   └── prompt_utils.py         # LLM 프롬프트 템플릿 관리
├── config/
│   ├── model_config.py         # LLM, 임베딩 등 모델/설정
│   └── settings.py             # 앱 전체 환경설정 (API 키, 서비스 URL 등)
├── models/
│   └── schema.py               # Pydantic 요청/응답 모델
├── data/
│   ├── scenarios/              # 금융사기 시나리오 JSON/YAML 파일들
│   └── quiz/                   # 금융퀴즈 데이터
├── api/
│   ├── routes.py               # API 엔드포인트 라우팅
│   └── dependencies.py         # FastAPI 의존성 관리
├── cli/
│   └── chat_tester.py          # CLI 기반 대화형 테스트 도구
├── requirements.txt
├── .env                        # 비밀키/환경변수
├── README.md                   # 프로젝트 설명, 실행 방법
└── tests/
    ├── test_chatbot.py         # 챗봇 기본 기능 테스트
    └── test_financial.py       # 금융 시나리오/퀴즈 테스트
```

### 4) 개발 및 통합 프로세스

* **1단계 - 독립 개발**: 텍스트 기반 CLI 환경에서 LangChain RAG+LLM 개발
  - `cli/chat_tester.py`를 통한 대화형 테스트
  - 금융교육/사기예방 시나리오 데이터 구축 및 테스트
  - RAG 검색 성능 최적화 및 LLM 응답 품질 향상

* **2단계 - API 서비스화**: REST API 엔드포인트 구현
  - FastAPI를 활용한 `/chat` 엔드포인트 구현
  - 텍스트 입력/출력 기반 API 서비스 테스트
  - 응답 시간 및 품질 최적화

* **3단계 - STT/TTS 통합**:
  - 명확한 인터페이스 설계로 STT/TTS 모듈과 손쉽게 통합
  - 텍스트 입력(`process_text_input()`) 함수가 STT 변환 텍스트를 받아 처리
  - 텍스트 출력이 TTS 모듈로 전달되어 음성 변환
  - 전체 파이프라인 통합 테스트 및 최적화

* **4단계 - 최종 통합 및 배포**:
  - 전체 시스템 통합 테스트 및 안정화
  - 실제 환경(인형 하드웨어)에서의 테스트 및 최적화

 
### 5) CLI 테스트 도구 (`cli/chat_tester.py`)

CLI 테스트 도구는 STT/TTS 모듈 없이도 LangChain RAG+LLM 챗봇의 기능을 직접 테스트할 수 있는 환경을 제공합니다:

* **대화형 인터페이스**: 터미널에서 직접 텍스트를 입력하고 응답을 확인
* **다양한 테스트 모드**:
  - 일반 대화 모드: 자유로운 질의응답 테스트
  - 금융퀴즈 모드: 미리 정의된 금융 퀴즈 시나리오 실행
  - 보이스피싱 시뮬레이션 모드: 가상의 사기 시나리오 테스트
  - 디버깅 모드: RAG 검색 결과, 프롬프트 등 중간 과정 표시
* **대화 기록 관리**: 대화 컨텍스트 유지 및 저장 기능
* **자동 테스트 시나리오**: 미리 정의된 테스트 케이스 자동 실행 기능

이 도구를 통해 STT/TTS와의 통합 이전에 RAG+LLM 파이프라인의 기능과 성능을 철저히 테스트하고 최적화할 수 있습니다. 이후 STT/TTS와 통합할 때 핵심 로직은 변경 없이 그대로 사용할 수 있도록 설계되었습니다.

### 6) 모듈 통합 구조

최종적인 시스템 통합은 다음과 같은 구조로 이루어집니다:

```
[사용자 음성] → [마이크] → [STT 모듈] → [텍스트] → [LangChain RAG+LLM] → [응답 텍스트] → [TTS 모듈] → [스피커] → [음성 출력]
```

* **STT 모듈과의 통합 인터페이스**:
  - STT 모듈이 변환한 텍스트가 `process_text_input()` 함수로 전달
  - 모듈 간 통신은 REST API 또는 직접 함수 호출로 구현
  - 텍스트 전처리 및 오류 처리 로직 포함

* **TTS 모듈과의 통합 인터페이스**:
  - LangChain 모듈의 텍스트 응답이 TTS 모듈로 전달
  - 응답 형식 및 메타데이터(감정, 강조 등) 포함 가능
  - 비동기 처리로 응답 지연 최소화

이러한 모듈식 설계를 통해 각 파트가 독립적으로 개발되고 테스트될 수 있으며, 최종 통합 시에도 인터페이스만 맞추면 원활한 연동이 가능합니다.

